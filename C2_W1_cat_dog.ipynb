{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1eetnals/coursera-tfcertificate/blob/main/C2_W1_cat_dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX4Kg8DUTKWO"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt2e4Hb8TPRq"
      },
      "source": [
        "**IMPORTANT NOTE:** This notebook is designed to run as a Colab. Click the button on top that says, `Open in Colab`, to run this notebook as a Colab. Running the notebook on your local machine might result in some of the code blocks throwing errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn-6c02VmqiN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sd9dQWa23aj",
        "outputId": "e782fdfc-5b2f-4a83-cbbf-464c40cfe24c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-27 06:16:49--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.201.212.130, 2600:1402:2000:1bb::e59, 2600:1402:2000:193::e59\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.201.212.130|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
            "\n",
            "/tmp/cats-and-dogs. 100%[===================>] 786.68M   109MB/s    in 6.3s    \n",
            "\n",
            "2022-01-27 06:16:56 (125 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# If the URL doesn't work, visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
        "# And right click on the 'Download Manually' link to get a new URL to the dataset\n",
        "\n",
        "# Note: This is a very large dataset and will take time to download\n",
        "# wget을 이요해서 웹서버에 접근하는 경우 인증서가 유효하지 않는다는 이유로 실패 되는 경우가 있음\n",
        "# 이런 경우 --no--check-certificate 옵션을 추가해서 인증서 체크하는 부분을 skip할 수 있음\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
        "    -O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "local_zip = '/tmp/cats-and-dogs.zip'  # colab tmp 폴더 안의 다운받은 파일 경로\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')   #zipfile 라이브러리의 ZipFile 클래스로 ZIP 파일 열기\n",
        "zip_ref.extractall('/tmp')  # extractall()을 이용해서 tmp 폴더에 압축 풀기\n",
        "zip_ref.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM851ZmN28J3",
        "outputId": "3fb19705-97de-4549-b100-9f31bf9e4851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12501\n",
            "12501\n"
          ]
        }
      ],
      "source": [
        "# 각 디렉토리에 몇 개의 강아지, 고양이 이미지가 존재하는지 출력\n",
        "# os.listdir() method는 지정한 디렉토리 내의 모든 파일과 디렉토리의 리스트를 return \n",
        "print(len(os.listdir('/tmp/PetImages/Cat/')))\n",
        "print(len(os.listdir('/tmp/PetImages/Dog/')))\n",
        "\n",
        "# Expected Output:\n",
        "# 12501\n",
        "# 12501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-QkLjxpmyK2"
      },
      "outputs": [],
      "source": [
        "# Use os.mkdir to create your directories\n",
        "# (os.mkdir을 사용해서 디렉토리 생성)\n",
        "# You will need a directory for cats-v-dogs, and subdirectories for training\n",
        "# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\n",
        "# (cats-v-dogs를 위한 디렉토리와 training, testing을 위한 하위 디렉토리 필요. 그 다음으로는 cats, dogs를 위한 하위 디렉토리 필요.)\n",
        "try:\n",
        "\n",
        "  # directory 만들기\n",
        "  ### START YOUR CODE HERE\n",
        "  os.mkdir('/tmp/cats-v-dogs')  \n",
        "  os.mkdir('/tmp/cats-v-dogs/training')\n",
        "  os.mkdir('/tmp/cats-v-dogs/testing')\n",
        "  os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
        "  os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
        "  os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
        "  os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
        "\n",
        "\n",
        "  ### alternate solution / 다른 표현 방법\n",
        "  # classes = ['cats','dogs']\n",
        "  \n",
        "  # for class_name in classes:\n",
        "  #     os.makedirs(os.path.join(\"/tmp/cats-v-dogs\", \"training\", class_name))\n",
        "  #     os.makedirs(os.path.join(\"/tmp/cats-v-dogs\", \"testing\", class_name))\n",
        "\n",
        "  ### END YOUR CODE HERE\n",
        "except OSError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbTJfiOX1Hf-"
      },
      "source": [
        "생성된 디렉토리의 구조\n",
        "\n",
        "*   cats-v-dogs\n",
        "  *   training\n",
        "      *   dogs \n",
        "      *   cats\n",
        "  *   testing\n",
        "      *   dogs\n",
        "      *   cats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvSODo0f9LaU",
        "outputId": "05e0f645-fa79-4727-b9a2-899540a1a197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "666.jpg is zero length, so ignoring.\n",
            "11702.jpg is zero length, so ignoring.\n"
          ]
        }
      ],
      "source": [
        "# Write a python function called split_data which takes \n",
        "# (split_data라고 불리는 파이썬 함수를 작성하여 다음을 취함)\n",
        "# a SOURCE directory containing the files\n",
        "# (파일이 들어있는 SOURCE directory)\n",
        "# a TRAINING directory that a portion of the files will be copied to\n",
        "# (파일의 일부가 복사될 TRAINING directory)\n",
        "# a TESTING directory that a portion of the files will be copie to\n",
        "# (파일의 일부가 복사될 TESTING directory)\n",
        "# a SPLIT SIZE to determine the portion\n",
        "# (복사할 부분을 결정하는 SPLIT SIZE)\n",
        "# The files should also be randomized, so that the training set is a random\n",
        "# X% of the files, and the test set is the remaining files\n",
        "# (training set가 파일의 X%가 랜덤이고 test set가 나머지 파일이 되도록 파일을 랜덤화해야함)\n",
        "# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9\n",
        "# (예를 들어, SOURCE가 PetImages/Cat이고 SPLIT SIZE가 .9인 경우)\n",
        "# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir\n",
        "# and 10% of the images will be copied to the TESTING dir\n",
        "# (# 그러면 PetImages/Cat의 90%의 이미지가 TRAINING dir에 복사되고 이미지의 10%가 TESTING dir로 복사됨)\n",
        "# Also -- All images should be checked, and if they have a zero file length,\n",
        "# they will not be copied over\n",
        "# (또한 -- 모든 이미지를 검사해야하며 파일 길이가 0인 경우 복사되지 않음)\n",
        "#\n",
        "# os.listdir(DIRECTORY) gives you a listing of the contents of that directory\n",
        "# (os.listdir(Directory)는 해당 디렉토리의 내용 목록을 제공)\n",
        "# os.path.getsize(PATH) gives you the size of the file\n",
        "# (os.path.getsize(PATH)는 파일 크기를 제공)\n",
        "# copyfile(source, destination) copies a file from source to destination\n",
        "# (copyfile(source, destination)은 source에서 destination으로 파일을 복사)\n",
        "# random.sample(list, len(list)) shuffles a list\n",
        "# (random.sample(list, len(list))은 목록을 섞음)\n",
        "\n",
        "# 이미지 복사하기\n",
        "# Cat 폴더에 있던 고양이 이미지를 training/cats 디렉토리와 testing/cats 디렉토리에 나누어 저장\n",
        "# Dog 폴더에 있던 강아지 이미지를 training/dogs 디렉토리와 testing/dogs 디렉토리에 나누어 저장\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "\n",
        "  ### START YOUR CODE HERE\n",
        "  files = []  #파일을 담아줄 리스트 생성\n",
        "  for filename in os.listdir(SOURCE):   #SOURCE 디렉토리에서 데이터들을 하나 하나 꺼냄\n",
        "    file = SOURCE + filename \n",
        "    # SOURCE의 경로(/tmp/PetImages/Dog/)+ 파일 이름(dog.123) 형식으로 데이터들은 하나 하나 모임\n",
        "    if os.path.getsize(file) > 0:\n",
        "    # 위에서 나온 것처럼 사이즈가 0 초과일 때만 진행  \n",
        "      files.append(filename)\n",
        "      #통과한 데이터들 만들어놓은 file 리스트에 담기\n",
        "    else:\n",
        "      print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "  training_length = int(len(files) * SPLIT_SIZE)\n",
        "  # 파일을 split_data 함수로 여러 주머니에다가 담아주어도, 파일의 총량은 변하지 않음\n",
        "  # (주머니 안의 파일 갯수*나눠진 주머니의 갯수 = 총 파일의 갯수)\n",
        "  testing_length = int(len(files) - training_length)\n",
        "  shuffled_set = random.sample(files, len(files))\n",
        "  training_set = shuffled_set[0:training_length]  # 섞는 범위 지정\n",
        "  testing_set = shuffled_set[-testing_length:]\n",
        "\n",
        "  for filename in training_set:\n",
        "    this_file = SOURCE + filename\n",
        "    # (/tmp/PetImages/Dog/)+(dog.123)의 형식을 this_file에 저장   \n",
        "    destination = TRAINING + filename\n",
        "    # 트레이닝 데이터들이 담긴 경로+(dog.123)의 형식으로 destination에 저장\n",
        "    copyfile(this_file, destination)\n",
        "    # copyfile 함수를 사용해 this_file을 destination에 복사\n",
        "    \n",
        "  for filename in testing_set:\n",
        "    this_file = SOURCE + filename\n",
        "    destination = TESTING + filename\n",
        "    copyfile(this_file, destination)\n",
        "\n",
        "  ### END CODE HERE\n",
        "\n",
        "  ### alternate solution / 다른 표현 방법\n",
        "  # # YOUR CODE STARTS HERE\n",
        "  # files = os.listdir(SOURCE)\n",
        "  # files = [file for file in files if os.path.getsize(os.path.join(SOURCE, file))>0]\n",
        "\n",
        "  # files = random.sample(files, len(files))\n",
        "  # limit = len(files) * SPLIT_SIZE\n",
        "\n",
        "  # for index, file in enumerate(files):\n",
        "  #   source = os.path.join(SOURCE, file)\n",
        "  #   if index < limit:\n",
        "  #     destination = os.path.join(TRAINING, file)\n",
        "  #   else:\n",
        "  #     destination = os.path.join(TESTING, file)  \n",
        "    \n",
        "  #   copyfile(source, destination)\n",
        "  # # YOUR CODE ENDS HERE\n",
        "\n",
        "\n",
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
        "\n",
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
        "\n",
        "# Expected output\n",
        "# 666.jpg is zero length, so ignoring\n",
        "# 11702.jpg is zero length, so ignoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwHXFhVG3786",
        "outputId": "61bf13bc-aa6b-4daa-d65c-637ffb3db58e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11250\n",
            "11250\n",
            "1250\n",
            "1250\n"
          ]
        }
      ],
      "source": [
        "# train, test할 강아지, 고양이 이미지 수 확인\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n",
        "\n",
        "# Expected output:\n",
        "# 11250\n",
        "# 11250\n",
        "# 1250\n",
        "# 1250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BQrav4anTmj"
      },
      "outputs": [],
      "source": [
        "# DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
        "# USE AT LEAST 3 CONVOLUTION LAYERS\n",
        "model = tf.keras.models.Sequential([\n",
        "    ### START CODE HERE\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    # 강아지와 고양이를 분류하는 이진 분류 문제이기 때문에 마지막 layer의 node 수는 1개, activation funcion으로는 sigmoid 사용\n",
        "    ### END CODE HERE\n",
        "])\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQrZfVgz4j2g",
        "outputId": "0549ea7c-3d64-457e-e6f9-32e5b6ece34d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22498 images belonging to 2 classes.\n",
            "Found 2500 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\" #YOUR CODE HERE\n",
        "# ImageDataGenerator 생성 (rescale=1./255를 설정해 0~1 사이의 값으로 정규화)\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.) #YOUR CODE HERE\n",
        "# train_datagen과 validation_datagen에서의 target_size는 무조건 동일해야 함\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR, #YOUR CODE HERE\n",
        "                                                    batch_size=100,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "VALIDATION_DIR = \"/tmp/cats-v-dogs/testing/\" #YOUR CODE HERE\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255.) #YOUR CODE HERE\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, #YOUR CODE HERE\n",
        "                                                              batch_size=100,\n",
        "                                                              class_mode='binary',\n",
        "                                                              target_size=(150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 22498 images belonging to 2 classes.\n",
        "# Found 2500 images belonging to 2 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMFNJZmTCZv6"
      },
      "source": [
        "Note: You can ignore the `UserWarning: Possibly corrupt EXIF data.` warnings.\n",
        "\n",
        "참고: 'UserWarning: EXIF 데이터가 손상될 수 있습니다.`는 경고를 무시해도 됨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "5qE1G6JB4fMn",
        "outputId": "25c21849-8d1f-47b2-ee3e-da3e8af6d336"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 18/225 [=>............................] - ETA: 7:41 - loss: 1.7367 - accuracy: 0.5500"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 512s 2s/step - loss: 0.7317 - accuracy: 0.6357 - val_loss: 0.5393 - val_accuracy: 0.7220\n",
            "Epoch 2/50\n",
            "225/225 [==============================] - 503s 2s/step - loss: 0.5156 - accuracy: 0.7506 - val_loss: 0.4695 - val_accuracy: 0.7772\n",
            "Epoch 3/50\n",
            "225/225 [==============================] - 502s 2s/step - loss: 0.4474 - accuracy: 0.7892 - val_loss: 0.6104 - val_accuracy: 0.6972\n",
            "Epoch 4/50\n",
            "225/225 [==============================] - 507s 2s/step - loss: 0.3842 - accuracy: 0.8251 - val_loss: 0.4258 - val_accuracy: 0.8100\n",
            "Epoch 5/50\n",
            "156/225 [===================>..........] - ETA: 2:31 - loss: 0.3292 - accuracy: 0.8551"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-54cb236101f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                               validation_data=validation_generator) # validation score을 확인하기 위해 validation data를 지정\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# The expectation here is that the model will train, and that accuracy will be > 95% on both training and validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# (여기서는 모델이 훈련되고 정확도는 훈련과 검증에서 모두 95% 초과가 예측될 것임.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Note that this may take some time.\n",
        "# Model 학습\n",
        "history = model.fit(train_generator,\n",
        "                              epochs=50,\n",
        "                              verbose=1,\n",
        "                              validation_data=validation_generator) # validation score을 확인하기 위해 validation data를 지정\n",
        "# The expectation here is that the model will train, and that accuracy will be > 95% on both training and validation\n",
        "# (여기서는 모델이 훈련되고 정확도는 훈련과 검증에서 모두 95% 초과가 예측될 것임.)\n",
        "# i.e. acc:A1 and val_acc:A2 will be visible, and both A1 and A2 will be > .9\n",
        "# (즉, acc:A1, val_Acc:A2가 표시되고 A1, A2 모두 >.9가 됨)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWZrJN4-65RC"
      },
      "outputs": [],
      "source": [
        "# model 분석\n",
        "# train data에서의 accuracy, loss 그리고 validation data에서의 accuracy, loss를 이용하여 모델을 개선\n",
        "# 이 값을 이용해 현재 overfitting이 일어나고 있는지, underfitting이 일어나고 있는지, 어떠한 클래스를 잘 예측하지 못하는지 등 파악 가능\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "# Desired output. Charts with training and validation metrics. No crash :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUt4KsPFTY33"
      },
      "source": [
        "**Important Note:** Due to some compatibility issues, the following code block will result in an error after you select the images(s) to upload if you are running this notebook as a `Colab` on the `Safari` browser. For `all other broswers`, continue with the next code block and ignore the next one after it.\n",
        "\n",
        "The ones running the `Colab` on `Safari`, comment out the code block below, uncomment the next code block and run it.\n",
        "\n",
        "**중요 참고:** 일부 호환성 문제로 인해 'Safari' 브라우저에서 이 노트북을 'Colab'으로 실행하는 경우 업로드할 이미지를 선택한 후 다음 코드 블록에 오류가 발생한다. 다른 모든 브라우저에 대해서는 다음 코드 블록을 계속 진행하고 다음 코드 블록은 무시합니다.\n",
        "\n",
        "'Safari'에서 'Colab'를 실행하는 사람들은 아래의 코드 블록을 주석으로 남겨 다음 코드 블록을 풀고 실행한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqL6FYUrtXpf"
      },
      "outputs": [],
      "source": [
        "# Here's a codeblock just for fun. You should be able to upload an image here \n",
        "# and have it classified without crashing\n",
        "# ()\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a dog\")\n",
        "  else:\n",
        "    print(fn + \" is a cat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbAkZEAqTg71"
      },
      "source": [
        "For those running this `Colab` on `Safari` broswer can upload the images(s) manually. Follow the instructions, uncomment the code block below and run it.\n",
        "\n",
        "Instructions on how to upload image(s) manually in a Colab:\n",
        "\n",
        "1. Select the `folder` icon on the left `menu bar`.\n",
        "2. Click on the `folder with an arrow pointing upwards` named `..`\n",
        "3. Click on the `folder` named `tmp`.\n",
        "4. Inside of the `tmp` folder, `create a new folder` called `images`. You'll see the `New folder` option by clicking the `3 vertical dots` menu button next to the `tmp` folder.\n",
        "5. Inside of the new `images` folder, upload an image(s) of your choice, preferably of either a horse or a human. Drag and drop the images(s) on top of the `images` folder.\n",
        "6. Uncomment and run the code block below. \n",
        "\n",
        "\n",
        "'Safari' 브라우저에 이 'Colab'을 실행 중인 사용자는 수동으로 이미지를 업로드할 수 있다. 지시사항에 따라 아래 코드 블록의 주석을 풀고 실행하라.\n",
        "\n",
        "Colab에서 수동으로 이미지를 업로드하는 방법:\n",
        "\n",
        "1. 왼쪽 메뉴 모음에서 '폴더' 아이콘을 선택\n",
        "2. '..'라는 이름의 '화살표가 위를 향하고 있는 폴더'를 클릭\n",
        "3. 'tmp'라는 이름의 폴더를 클릭.\n",
        "4. 'tmp' 폴더 안에는 '이미지'라는 새로운 폴더를 생성. 'tmp' 폴더 옆에 있는 '세로점 3개' 메뉴 버튼을 클릭하면 '새 폴더' 옵션이 나타남.\n",
        "5. 새로운 '이미지' 폴더 안에 말이나 사람 중 원하는 이미지를 업로드. 이미지를 '이미지' 폴더 위에 끌어다놓기.\n",
        "6. 아래의 코드 블록을 제거하고 실행."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fmIwKFSThXv"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from keras.preprocessing import image\n",
        "# import os\n",
        "\n",
        "# images = os.listdir(\"/tmp/images\")\n",
        "\n",
        "# print(images)\n",
        "\n",
        "# for i in images:\n",
        "#  print()\n",
        "#  # predicting images\n",
        "#  path = '/tmp/images/' + i\n",
        "#  img = image.load_img(path, target_size=(150, 150))\n",
        "#  x = image.img_to_array(img)\n",
        "#  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "#  images = np.vstack([x])\n",
        "#  classes = model.predict(images, batch_size=10)\n",
        "#  print(classes[0])\n",
        "#  if classes[0]>0.5:\n",
        "#    print(i + \" is a dog\")\n",
        "#  else:\n",
        "#    print(i + \" is a cat\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "C2_W1_cat_dog.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}